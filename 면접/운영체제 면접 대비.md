# 운영체제 면접 대비

[TOC]

## 운영체제란

컴퓨터 하드웨어 바로 위에 설치되어 사용자 및 다른 모든 소프트웨어와 하드웨어를 연결하는 소프트웨어입니다.

컴퓨터 시스템의 자원을 효율적으로 관리하기 위해서 사용합니다. 프로세서,메모리,입출력 장치등의 관리



## Mode bit

사용자 프로그램의 잘못된 수행으로 다른 프로그램,운영체제에 피해가 안가게 하기 위해서 어떤 프로그램 수행 중인지 표시하는 것

1:사용자모드이면 사용자 프로그램 0:모니터모드이면 OS코드 수행 , 보안을 해칠 수 있는 중요한 명령어는 모니터모드에서만 수행 가능한 특권명령(입출력 장치,하드웨어에 직접적 접근)으로 규정



## 인터럽트

프로그램을 실행하는 도중에 예외 상황이 발생 시 실행중인 작업을 즉시 중단하고, 발생된 상황에 대한 우선 처리가 필요함을 CPU에게 알리는 것

왜 함? 입출력 연산이 CPU 명령 수행속도보다 훨씬 느리기 때문 CPU를 계속 활용할려고

인터럽트 당한 시점의 레지스터와 program counter를 PCB에 저장하고 CPU의 제어를 인터럽트 처리 루틴에 넘긴다.

폴링방식보다 훨씬 좋음: 폴링 - 계속 체크하느라 원래 하던일에 집중x



Interrupt : 하드웨어가 발생시킨 인터럽트 (전원 이상, 외부 신호, 입출력)

Trap : 소프트 웨어 인터럽트 

​	Exception : 프로그램 오류 발생

​	System call: 프로그램이 커널 함수 호출



## 동기식, 비동기식 입출력

동기식 입출력

I/O 요청후 입출력 작업 완료된 후에 제어권이 사용자 프로그램에 넘어감

1) I/O 끝날 때까지 CPU 낭비

2) I/O 끝날 때까지 다른 프로그램에 CPU 줌



비동기식 입출력

I/O가 시작된 후 제어가 곧바로 사용자 프로그램에 넘어감



I/O의 완료는 인터럽트로 알려줌



## 프로세스의 주소 공간

프로그램이 CPU에 의해 실행되면 프로세스가 생성되고 메모리에 프로세스 주소 공간이 할당

코드 : 프로그램 소스 코드 저장

데이터: 전역 변수 저장

스택: 함수, 지역 변수 저장



왜 이렇게 나눔? 

최대한 데이터 공유하여 메모리 사용량 줄이기 위함. code는 같은 프로그램 자체에서는 모두 같은 내용이기 때문에 공유

스택과 데이터 구분하는 이유는 함수 실행의 경우 스택에 쌓는듯이 실행이 됨. 데이터쪽에 여러 군데서 쓰이는애를 전역으로 해서 메모리 아낌



## 커널 주소 공간

code : 시스템 콜, 인터럽트 처리 코드, CPU,메모리 등 자원관리를 위한 코드

data: PCB, CPU,Memory 자원 관리하기 위한 자료구조 저장

stack: 각 process의 커널 스택 저장 , 프로세스마다 별도의 스택



## PCB

운영체제가 각 프로세스를 관리하기 위해 프로세스 당 관리하는 정보

OS가 관리상 사용하는 정보

​	Process state, Process ID

​	scheduling information, priority

CPU 수행 관련 하드웨어 값

​	program counter, registers

Doubly - Linked list 방식으로 관리 : 삽입,삭제가 잦음 프로세스 실행,종료가 계속 반복되기 떄문 따라서 삽입 삭제에 용이한 이거 쓰는듯



## Context Switch

CPU를 한 프로세스에서 다른 프로세스로 넘겨주는 과정

OS는 CPU를 뺏긴 프로세스 상태를 그 프로세스 PCB에 저장 -> CPU 얻는 프로세스 상태를 PCB에서 읽어옴



## Scheduler

job que 프로세스 전체

ready que 메모리에 올라와 있으면서 CPU 잡아서 실행되기를 기다리는 애들

Device que I/O device의 처리를 기다리는 프로세스들



Long-term scheduler

프로세스 중 어떤 것들을 ready que로 보낼 것인지 결정, time sharing system에는 없음

Short-term scheduler

ready que의 프로세스 중 어떤 것을 CPU를 줘서 실행시킬지 - 빨라야 함

medium-term scheduler (swapper) 메모리에 올라와 있는 프로세스들 중 어떤 것을 디스크로 쫓아 낼것인지 결정



## Thread

프로세스 안에서 실행되는 여러 작업 흐름

다른 스레드들과 code,data를 공유하고 stack만 따로 할당 받음



멀티쓰레드 -> 높은 throughput과 성능 향상,병렬성

하나의 스레드가 block되도 다른 thread가 일을 계속함 -> 반응성이 좋아짐



## 멀티 쓰레드 vs 멀티 프로세스

멀티 프로세스: CPU 여러개 장착해 동시에 여러개 프로세스 처리

​	장점: 안정성(메모리 침범 안함)

​	단점: 각각 독립된 메모리 영역, 작업량 많을수록 오버헤드 , context switching으로 인한 성능 저하



멀티 쓰레드: 한 프로세스에서 여러 스레드로 다수의 작업 동시 처리

​	장점: 메모리 공유해서 자료 공유 가능하고 자원 손실 감소

​	단점: 안전성 문제 하나 스레드가 데이터 공간 망가뜨리면, 모든 스레드가 작동 불능 상태

단점 보완위해 Ciritcal Section 기법을 통해 대비



## 시스템 콜

fork() 자식 프로세스 생성

새 주소공간 생성함 부모거 복사해서



exec() 다른 프로그램 실행

그 메모리 공간을 새 프로그램으로 덮어씌움 



wait() 자식이 종료될때까지 부모 sleep, child 종료되면 부모 깨움



exit() 프로세스 종료

할당된 자원 다 풀어주고 부모에 알림



## IPC(InterProcess Communication)

프로세스간 통신 해야할 때 커널의 IPC 설비를 사용해 통신

1. 익명 PIPE

파이프로 2개 프로세스 연결, 한쪽은 쓰기만 한쪽은 읽기만 한쪽방향 통신만 가능, 통신할 양쪽이 명확한 경우 씀(자식,부모 등) - 장점: 간단하고 단점: 양방향 위해 2개만들면 구현 복잡

2. Named PIPE(FIFO)

전혀 모르는 상태 프로세스들 사이 통신에 사용, 역시 한방향 통신

3. Message Queue

입출력 방식은 Named 파이프와 동일 데이터 흐름이 아니라 메모리 공간, 사용할 데이터에 번호 붙여 여러 프로세스가 동시에 데이터 쉽게 다룸

4. 공유 메모리

데이터 자체를 공유하도록 지원

프로세스가 공유 메모리 할당을 커널에 요청하면, 커널은 해당 프로세스에 메모리 공간 할당, 모든 프로세스는 해당 메모리 영역에 접근 가능 -> 중개자 없이 메모리 접근 할 수 있어 IPC중 가장 빠르게 동작



## CPU Scheduling

CPU, I/O 장치 등 시스템 자원을 효율적으로 사용하기 위해



### FCFS

먼저 온애들 먼저 실행

### SJF

CPU burst time 젤 짧은애 먼저 실행

문제점: burst 긴 애들 starvation

### SRTF

현재 수행중인 프로세스 CPU burst time보다 더 짧은 CPU burst time을 가지는 새로운 프로세스가 도착하면 CPU 뺴앗김

문제점: starvation



CPU burst time 은 과거 기록으로 추정해서 사용



### Priority Scheduling

우선순위 높은 애에게 CPU 할당

문제점: starvation  -> 해결: againg 오래 기다린애 우선순위 높여줌



### Round Robin

각 프로세스는 동일한 크기의 할당 시간(time quantum)q

timer로 재서 시간 다되면 interrupt 발생시켜서 뺏음. 뺏긴애는 ready queue 맨 뒤로 감

q가 너무크면 FCFS 너무 작으면 오버헤드커짐(context switching)



### Multilevel queue

Ready queue를 여러개로 분할, 각 큐별로 독립적 scheduling algorithm

큐에 대해 스케줄링 

시간을 분배하거나 우선순위 정해서 한 큐 다하면 딴 큐 하고 이런 식



### Multilevel Feedback queue

큐 여러개 해서 수행시간 짧은 프로세스들에 우선순위 길면 밑으로 쫓겨남

aging을 이렇게 구현



## Race condition

공유 자원에 대해 여러 프로세스가 동시에 접근할 때, 자료의 일관성을 해치는 결과가 나타날 수 있는 상태



Race condition이 발생하는 경우

1) 커널 작업을 수행하는 중에 인터럽트 발생

​	문제점: 커널 모드에서 데이터를 로드하여 작업을 수행하다가 인터럽트가 발생하여 같은 데이터를 조작하는 경우

​	해결책: 커널모드에서 작업 수행시 인터럽트를 disable 시켜 CPU 제어권을 못 가져가게 한다

2) 프로세스가 System call 을 하여 커널 모드로 진입하여 작업 수행 도중 문맥 교환 발생 시

​	문제점: 프로세스1이 커널모드에서 데이터 조작 도중 시간이 초과되어 CPU 제어권이 프로세스 2로 넘어가 같은 데이터 조작하는 경우

​	해결법: 프로세스가 커널모드에서 작업 하는 경우 시간이 초과되어도 CPU 제어권이 다른 프로세스에게 넘어가지 않도록 함

3) 멀티 프로세스 환경에서 공유 메모리 내의 커널 데이터에 접근할 때

​	문제점: 멀티 프로세서 환경에서 2개의 CPU가 동시에 커널 내부의 공유 데이터에 접근하여 조작하는 경우

​	해결법: 커널 내부에 있는 각 공유 데이터에 접근할 때마다, 그 데이터에 대한 lock/unlock을 함



## Process Synchronization

Race conditon 막기 위해 concurrent process는 동기화되야 함



critical section: 공유 데이터 접근하는 코드



### 프로그램적 해결법의 충족 조건

- Mutual Exclusion : 프로세스 A가 critical section 부분을 수행 중이면 다른 모든 프로세스들은 그들의 critical section에 들어갈 수 없음
- Progress : 아무도 critical section에 들어가 있지 않은 상태에서 거기 들어갈려는 프로세스 있으면 들가게 해줘야 함
- Bounded Waiting : critical section 들어간다 요청 후에 그 요청 허용될 때까지 다른 프로세스가 거기 들어가는 횟수에 한계가 있어야함



### Semaphores

소프트웨어 상에서 Critical Section 문제를 해결하기 위한 동기화 도구

spin lock 버전

P(S) 

```
while(S<= 0) do nothing;
s--;
```



V(S)

```
S++;
```

busy wait 문제 : 계속 while 문돌면서 사용가능한지 확인해야함 (spin lock) -> 실패한 프로세스 block 시키고 자리나면 꺠우는 방식으로 해결



sleep lock 버전

P(S)

```
S.value--;
if(S.value < 0)
	add this process to S.L;
	block();
```

V(S)

```
s.value++;
if(S.value <= 0)
	remove a process P from S.L;
	wakeup(P);
```



세마포의 경우 데드락이 발생할 수 있음 , 데드락: 프로세스가 계속 상대가 가진 자원이 필요해서 영원히 기다리는거

둘 이상 프로세스가 실행되는데 자원 2개 필요 근데 1개를 서로 나눠가짐 -> 데드락(영원히 블락댐)



세마포 문제점:

코딩하기 힘듬

실수 한번에 데드락 생길 수 있음



이 문제점 해결하는거 -> 모니터



### Monitor

동기화 도구 , 공유자원에 접근할 때 모니터에서 정의한 프로시져로만 접근하게 하고 동시에 여러개 실행 안되게 모니터에서 통제

condition variabl x,y 사용 , wait과 signal연산으로만 접근 가능

x.wait(); 이거 실행하면 다른 프로세스가 x.signal()하기전까지 block

x.signal() 하나의 suspend된 프로세스 resume



## Deadlock

프로세스들이 서로가 가진 자원(semaphore, CPU cycle, I/O device, memory space 등)을 기다리며 block 된상태



### 발생 4가지 조건

상호배제: 해당 자원 한 프로세스 사용시 다른 프로세스는 사용 못함

비선점: 해당 자원 한 프로세스 사용시 다른 프로세스가 뻇을 수 없음

점유대기: 프로세스가 자원을 점유하고 대기

순환대기: A는 B가가진 자원 원하고 B는 C자원 원하고 C는 A자원 원하는 경우



### 처리방법

#### Deadlock Prevention

점유대기 -> 기다릴때 자원 아무것도 안 가지게 함

비선점 -> 자원 뺏음

순환 대기 -> 순서 정해서 순서대로 자원 할당

CPU 이용률 저하, 쓰루풋 감소, starvation

#### Deadlock Avoidance

미리 조사해서 데드락으로부터 safe할 때만 자원 할당

자원 할당 그래프, Banker`s algorithm 사용

-> 오버헤드 졸라큼

#### Deadlock Detection & Recovery

자원할당 그래프 그려서 확인, 사이클 조사하는지 확인해서  있으면 프로세스 데드락 걸린거 다끄거나 하나씩 끔

-> starvation 문제 동일한 프로세스가 계속 victim으로 선정되는 경우, victim 선정된 횟수 많으면 선정안하게 함

#### Deadlock Ignorance

데드락 거이 발생안해서 아무 조치 안함

사용자가 직접 프로세스 끄는 식으로 대처 UNIx,Window등 대부분의 OS가 채택



## 메모리 관리

### 주소 관리

logical -> physical address , MMU사용해 서 주소 바인딩(로드 타임, 컴파일 타임, 런타임)

MMU: logicla physical address 매핑



### 다이나믹 로딩

프로세스 전체 메모리에 올리지 않고 해당 루틴이 불려질 때 메모리에 올림(오류 처리 루틴 등-가끔 사용되는 많은 양 코드)



### Overlays

메모리에 프로세스 중 실제 필요한 정보만 올림



### Swapping

프로세스를 일시적으로 메모리에서 디스크로 쫓아냄



### Dynamic Linking

Linking을 실행시간까지 미룸

라이브러리가 실행시 연결됨, OS 도움 필요, 



### 메모리 할당 방법

#### 연속 할당

1) 고정 분할: 물리적 메모리 몇개의 영구적 분할로 나눔, 분할에 하나 프로그램 적재

동시에 메모리에 올리는 프로그램 수 제한, 최대 수행 가능 프로그램 크기 제한

내부 단편화, 외부단편화 발생

2) 가변 분할 방식:

프로그램 크기에 맞게 할당 -> 외부 단편화 발생

hole(가용 메모리공간)을 찾아서 거기에 프로그램 올림 best-fit(젤 작은거),worst-fit(젤 큰거),first-fit(젤먼저 찾는거)

compaction: 사용중 메모리 영역 한곳으로 몰고 hole을 한곳으로 몰아 매우 큰 block 만듬, 오버헤드 개큼

#### 불연속 할당

1) Paging: process의 virtual memory를 동일한 사이즈의 page 단위로 나눔

물리적 메모리는 동일한 사이즈 프레임으로 나눠서 매핑함, 외부 단편화 x 내부 단편화 O

매핑은 페이지 테이블 생성, 페이지 테이블 크기가 너무 크면 계층적 페이지 테이블 구성해서 해결

모든 메모리 접근 연산 -> 페이지 테이블 접근, 실제 데이타 접근 총 2번 해야함

속도 향상 위해 고속의 TLB (cache) 사용

테이블 위한 메모리 낭비 심함

2) Segmentation: 의미 단위인 여러개 segment로 구성 code,data,stack 부분이 하나의 세그먼트

공유, 보안에 효과적, 외부 단편화 발생 fisrt fit/ best fit 사용

테이블 작음 -> 세그먼트가 몇개 안됨



## 가상 메모리

프로세스 전체가 메모리 내에 올라오지 않더라도 실행이 가능하도록 하는 기법, 

더 많은 프로그램 동시 실행, 응답시간 유지 -> CPU 이용률, 스루풋 증가



### 요구 페이징

실제로 필요할 때 page를 메모리에 올림



### valid / invalid bit

invalid: 페이지가 메모리 내에 없을 경우



### page fault 발생시

invalid page 접근시 MMU 트랩 발생 시킴

kerner mode에서 page fault handler가 실행

1) 빈 페이지 프레임, 없으면 뻇어옴

2) 디스크에서 메모리로 페이지 가져옴

​	disk I/O가 끝나기까지 CPU 뺏김 block

​	다 읽으면 페이지 테이블에 valid로 바꿈

​	ready queue에 넣음

3) 프로세스가 CPU 잡고 다시 run



### page 교체 전략

#### Optimal algorithm

가장 먼 미래에 참조되는 page를 교체, 어케 암? 모름 구현 어려움 옛날 기록으로 추측?



#### FIFO

젤 먼저 들온애를 내쫓음



#### LRU

가장 오래전에 참조된거 지움

연결리스트로 구현

#### LFU

참조횟수 젤 적은 페이지 지움

힙으로 구현



### 캐시

한정된 빠른 공간에 요청된 데이터를 저장해 두었다가 후속 요청시 캐시로부터 직접 서비스하는 방식 : 시간이 빨라야 함

Paging system의 경우 페이지가 이미 메모리에 존재하는 경우 OS가 참조시각 등의 정보를 알 수 없음

#### 캐시의 지역성

CPU가 어떤 데이터를 원할지 예측하기 위해 (적중율 높이기 위해) 지역성 원리 차용

시간 지역성: 최근에 참조된 주소의 내용은 곧 다시 참조

공간 지역성: 대부분 프로그램이 참조된 주소와 인접한 주소 내용을 참조



#### 캐싱 라인

캐시가 가까이 있더라도 일일이 완탐해서 데이터 찾으면 오래 걸림 -> 빠르게 하기 위해 데이터를 묶음으로 저장 (캐싱 라인)

데이터에 데이터의 메모리 주소등을 기록해둔 태그를 담 -> 이런 태그들의 묶음 캐싱라인, 메모리로부터 가져올 때 캐싱라인 기준으로 가져옴

Full Associative, Set Associative, Direct Map



### 페이징 시스템에서 LRU, LFU가 가능한가?

OS가 어떤 페이지의 접근시간, 빈도를 알 수 없어서 불가능, 메모리에 이미 있는 애들을 참조하면 OS에 CPU가 안넘어오기 떄문



### 페이지 프로세스에 할당하는 전략

각 프로세스에 얼마만큼의 페이지 할당?

명령어 수행을 위해 필요한 최소 프레임이 있음

loop를 구성하는 페이지들은 한번에 할당하면 좋음



방식들

모든 프로세스에 똑같은 갯수 할당, 프로세스 크기에 비례해 할당, 프로세스 우선순위에 맞게 할당



### 페이지 Global, Local 교체 전략

Global 다른 프로세스 프레임 뺏기 가능

Local 지꺼만 함



### Thrashing

프로세스의 원활한 수행에 필요한 최소한의 page frame 수 할당 받지 못한 경우 발생

page fault rate 매우 높아짐 CPU utilization 낮아짐 , CPU는 멀티프로그래밍 degree 늘려야 된다고 판단 -> 또 다른 프로세스가 시스템에 추가, 프로세스는 할당된 frame 수가 더 감소 -> 프로세느는 page의 swap in/out으로 매우 바쁨 -> CPU는 놈-> 쓰루풋 개낮아짐



### Working-Set

프로세스는 특정 시간동안 일정 장소만을 집중적으로 참조

짐중적으로 참조되는 해당 page들의 집합을 locality set



지역성에 기반해 프로세스가 일정시간 동안 원활히 수행되기 위해 한꺼번에 메모리에 올라와 있어야 하는 page들을 Working set이라 함

Working set 모델에서는 Working set 전체가 메모리에 올라와 있어야 프로세스 실행, 그렇지 않으면 프레임 다 반납하고 suspend

thrashing 방지, MPD(Multiprogramming degree) 결정



window size dt라 할 때 working set = t ~ t+dt 사이에 참조된 페이지들,

working set에 속한 page는 메모리에 유지, 아니면 버림 ( 참조 된후 dt시간동안 페이지를 메모리에 유지한 후 버림)



### Page size의 결정

Page size를 감소시키면 페이지 수증가 -> 페이지 테이블 크기 증가 -> 내부단편화 감소 -> Disk transfer의 효율성 감소 -> 필요한 정보만 메모리에 올라와 메모리 이용 효율적 ,

트렌드는 큰 페이지 사이즈



